###### PBertKla
# 目录结构
```
/mnt/alamo01/users/yuansongwei7/PBertKla/
├── Code/
│   ├── predict_fasta.py
│   └── proteinbert/   ← ProteinBERT 核心源码（完备）
├── Data/
│   ├── PBertKla_train.csv
│   ├── PBertKla_test.csv
│   └── mydata.csv（可选）
├── PBertKla.ipynb     ← 主 Notebook（训练 & 预测）
├── PD-L1.fasta
├── SDHA.fa
├── README.md
└── Results/

```

#准备

## 环境准备

```
micromamba create -n pbertkla python=3.8 -y
micromamba activate pbertkla
```

##  Installation has been tested in Ubuntu 22.04 system with Python 3.7, and its working time was about 25 mins.

PBertKla uses the following dependencies:

tensorflow (2.4.0)

tensorflow_addons (0.12.1)

numpy (1.20.1)

pandas (1.2.3)

h5py (2.10.0)

lxml (4.3.2)

pyfaidx (0.5.8)
```
# 进入你的主目录
cd /mnt/alamo01/users/yuansongwei7

# 创建环境目录
micromamba create -p ./pbertkla_env python=3.7 -y
micromamba activate ./pbertkla_env

# 设置 pip 源为官方 PyPI
mkdir -p ~/.pip
cat > ~/.pip/pip.conf <<EOF
[global]
index-url = https://pypi.org/simple
timeout = 120
EOF

# 安装 PBertKla 所需依赖
pip install tensorflow==2.4.0 tensorflow_addons==0.12.1 \
    numpy==1.19.5 pandas==1.2.3 h5py==2.10.0 lxml==4.3.2 pyfaidx==0.5.8 \
    -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## 下载PBertKla代码
```
cd /mnt/alamo01/users/yuansongwei7/PBertKla
wget https://github.com/laihongyan/PBertKla/archive/refs/heads/main.zip -O PBertKla-main.zip
unzip PBertKla-main.zip
mv PBertKla-main/* ./
rm -rf PBertKla-main PBertKla-main.zip
```


## 在当前 micromamba 环境注册 Jupyter kernel
```
micromamba activate /mnt/alamo01/users/yuansongwei7/pbertkla_env
python -m ipykernel install --user --name proteinbert --display-name "proteinbert"
pip install scikit-learn==0.24.2 -i https://pypi.tuna.tsinghua.edu.cn/simple

```

## 集群运行 Notebook 训练与预测(papermill 自动运行 PBertKla.ipynb)
```
#!/bin/bash
# ======== PBertKla 集群运行脚本 ========

# 激活 micromamba 环境
source ~/micromamba/etc/profile.d/micromamba.sh
micromamba activate /mnt/alamo01/users/yuansongwei7/pbertkla_env

# 设置项目路径
PROJECT_DIR=/mnt/alamo01/users/yuansongwei7/PBertKla
INPUT_NB=$PROJECT_DIR/PBertKla.ipynb
OUTPUT_NB=$PROJECT_DIR/Results/PBertKla_out.ipynb

# 设置 Python 搜索路径
export PYTHONPATH=$PROJECT_DIR/Code:$PYTHONPATH
echo "✅ PYTHONPATH set to $PYTHONPATH"

# 打印环境信息
echo "Input Notebook:  $INPUT_NB"
echo "Output Notebook: $OUTPUT_NB"
python -c "import sys; print('Python Path:', sys.path)"

# 检查依赖
pip install -q scikit-learn==0.24.2 matplotlib==3.3.4 papermill jupyter
# 运行 Notebook
papermill $INPUT_NB $OUTPUT_NB

echo "✅ Notebook execution completed."

```

## 安装 Notebook 运行所需工具
pip install papermill nbconvert ipykernel
```

## 数据准备

```
pip install papermill nbconvert -i https://pypi.tuna.tsinghua.edu.cn/simple
mkdir -p /mnt/alamo01/users/yuansongwei7/pbertkla_data
cd /mnt/alamo01/users/yuansongwei7/pbertkla_data
git clone https://github.com/laihongyan/PBertKla.git（https://github.com/laihongyan/PBertKla/blob/main/README.md）
```

##  run_pbertkla.sh（训练模型）
```
#!/bin/bash
# ======== PBertKla 集群运行脚本 ========

# 激活 micromamba 环境
source /mnt/alamo01/users/yuansongwei7/micromamba/etc/profile.d/micromamba.sh
micromamba activate /mnt/alamo01/users/yuansongwei7/pbertkla_env

# 设置项目路径
PROJECT_DIR=/mnt/alamo01/users/yuansongwei7/PBertKla
INPUT_NB=$PROJECT_DIR/PBertKla.ipynb
OUTPUT_NB=$PROJECT_DIR/Results/PBertKla_out.ipynb

# 设置 Python 搜索路径（确保能找到 proteinbert）
export PYTHONPATH=$PROJECT_DIR/Code:$PYTHONPATH
echo "✅ PYTHONPATH set to $PYTHONPATH"

# 检查依赖
echo "🔧 Installing dependencies..."
pip install -q scikit-learn==0.24.2 matplotlib==3.3.4 papermill jupyter

# 打印环境信息
echo "Input Notebook:  $INPUT_NB"
echo "Output Notebook: $OUTPUT_NB"
python -c "import sys; print('Python Path:', sys.path)"

# 运行 Notebook
echo "🚀 Starting notebook execution..."
papermill $INPUT_NB $OUTPUT_NB

echo "✅ Notebook execution completed."
```

## PBertKla.ipynb
```
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS_DIR = '/mnt/alamo01/users/yuansongwei7/PBertKla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_PRC(y_true,y_pred,savepath):\n",
    "    with open(savepath+\"y_true.txt\",\"w\") as f:\n",
    "        f.write(str(y_true.tolist()))\n",
    "    with open(savepath+\"y_pred.txt\",\"w\") as f:\n",
    "        f.write(str(y_pred.tolist()))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    prc_auc = auc(recall, precision)\n",
    "\n",
    "    y_pred=np.around(y_pred,0).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    acc = (tp+tn)/(tn + fp+ fn + tp)   \n",
    "    sn = tp / (tp + fn)\n",
    "    sp = tn / (tn + fp)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # ROC\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUROC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    # PRC \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='orange', lw=2, label=f'PRC curve (AUPRC = {prc_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savepath+\"AUC_PRC.svg\",dpi=600)\n",
    "    \n",
    "    with open(savepath+\"results.txt\",\"w\") as f:\n",
    "        f.write(f'AUROC: {roc_auc:.4f}\\n')\n",
    "        f.write(f'AUPRC: {prc_auc:.4f}\\n')        \n",
    "        f.write(f'Accuracy: {acc:.4f}\\n')\n",
    "        f.write(f'Sensitivity (Recall): {sn:.4f}\\n')\n",
    "        f.write(f'Specificity: {sp:.4f}\\n')\n",
    "        f.write(f'Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n')\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PBertKla(item):\n",
    "    (batch_size,lr,seqlen) = item\n",
    "    BENCHMARK_NAME = 'Data/PBertKla'\n",
    "    # A local (non-global) binary output\n",
    "    OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "    UNIQUE_LABELS = [0, 1]\n",
    "    OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "    # Loading the dataset\n",
    "\n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s_train.csv' % BENCHMARK_NAME)\n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s_test.csv' % BENCHMARK_NAME)\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "    print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "\n",
    "    # Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "\n",
    "    pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "    # get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "    model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "            get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "    training_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "        keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "    ]\n",
    "\n",
    "    finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "            seq_len = seqlen, batch_size = batch_size, max_epochs_per_stage = 40, lr = lr, begin_with_frozen_pretrained_layers = True, \\\n",
    "            lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "\n",
    "    # Evaluating the performance on the test-set\n",
    "\n",
    "    results, confusion_matrix, y_true, y_pred = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \\\n",
    "            start_seq_len = seqlen, start_batch_size = batch_size)\n",
    "    savepath=BENCHMARKS_DIR+f'Results/'\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    roc=AUC_PRC(y_true,y_pred,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from IPython.display import display\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "\n",
    "def AUC_PRC(y_true, y_pred, savepath):\n",
    "    with open(savepath + 'y_true.txt', 'w') as f:\n",
    "        f.write(str(y_true.tolist()))\n",
    "    with open(savepath + 'y_pred.txt', 'w') as f:\n",
    "        f.write(str(y_pred.tolist()))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    prc_auc = auc(recall, precision)\n",
    "    y_pred = np.around(y_pred, 0).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "    sn = tp / (tp + fn)\n",
    "    sp = tn / (tn + fp)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUROC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='orange', lw=2, label=f'PRC curve (AUPRC = {prc_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savepath + 'AUC_PRC.svg', dpi=600)\n",
    "    with open(savepath + 'results.txt', 'w') as f:\n",
    "        f.write(f'AUROC: {roc_auc:.4f}\\n')\n",
    "        f.write(f'AUPRC: {prc_auc:.4f}\\n')\n",
    "        f.write(f'Accuracy: {acc:.4f}\\n')\n",
    "        f.write(f'Sensitivity (Recall): {sn:.4f}\\n')\n",
    "        f.write(f'Specificity: {sp:.4f}\\n')\n",
    "        f.write(f'Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n')\n",
    "    return roc_auc\n",
    "\n",
    "def PBertKla(item):\n",
    "    (batch_size, lr, seqlen) = item\n",
    "    BENCHMARK_NAME = 'PBertKla'\n",
    "    BENCHMARKS_DIR = '/mnt/alamo01/users/yuansongwei7/PBertKla/Data'\n",
    "    OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "    UNIQUE_LABELS = [0, 1]\n",
    "    OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, f'{BENCHMARK_NAME}_train.csv')\n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    train_set, valid_set = train_test_split(train_set, stratify=train_set['label'], test_size=0.1, random_state=0)\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, f'{BENCHMARK_NAME}_test.csv')\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "    print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "    pretrained_model_generator, input_encoder = load_pretrained_model(\n",
    "        download_model_dump_if_not_exists=False,\n",
    "        validate_downloading=False\n",
    "    )\n",
    "    model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC,\n",
    "        pretraining_model_manipulation_function=get_model_with_hidden_layers_as_outputs, dropout_rate=0.5)\n",
    "    training_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.25, min_lr=1e-05, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
    "    ]\n",
    "    finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'],\n",
    "             valid_set['seq'], valid_set['label'], seq_len=seqlen, batch_size=batch_size,\n",
    "             max_epochs_per_stage=40, lr=lr, begin_with_frozen_pretrained_layers=True,\n",
    "             lr_with_frozen_pretrained_layers=1e-02, n_final_epochs=1, final_seq_len=1024,\n",
    "             final_lr=1e-05, callbacks=training_callbacks)\n",
    "    results, cm, y_true, y_pred = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC,\n",
    "             test_set['seq'], test_set['label'], start_seq_len=seqlen, start_batch_size=batch_size)\n",
    "    savepath = os.path.join(BENCHMARKS_DIR, 'Results')\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    roc = AUC_PRC(y_true, y_pred, savepath)\n",
    "    weight_path = os.path.join(savepath, 'PBertKla_weights.h5')\n",
    "    model_generator.get_model().save_weights(weight_path)\n",
    "    print(f'✅ 模型权重已保存: {weight_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    item = (4, 5e-4, 256)\n",
    "    PBertKla(item)\n"
]

   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteinbert",
   "language": "python",
   "name": "proteinbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
```
